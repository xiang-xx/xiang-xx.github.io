[{"categories":null,"contents":" 关于 raft Raft1 是一种共识算法，它能够使得系统成员部分失效后，系统仍然能够工作。本质上是一个备份状态机，它具有以下特性：\n安全性：永远不会返回错误数据（尽管存在拜占庭故障、网络分区、延迟、丢包等） 高可用：只要大多数节点存活（互相之间能通讯，能被客户端访问到），系统就是可用的 共识日志不依赖时间（因为系统可能存在时间故障、严重延迟等） 一般情况下，只要集群大多数响应命令完成，则此命令就会完成，避免少量慢节点影响整体服务性能 Raft 部分思想受 Paxos、zab 等协议启发，但 Raft 协议简单很多：作者在论文中多次强调 Paxos 过于复杂，他们花了一年时间才真正搞懂 Paxos 究竟是如何工作的。而 Raft 协议的初衷就是创建一个更简单的共识算法，更简单意味着可以被更多人学习、理解，能更好的在生产中实现、使用。\n这个网站2使用分步动画形式很好的解释了 raft 的运行方式，通过它可以对 raft 协议有大致的认识。\nRaft 共识算法概要 Raft 算法要求先选出 leader，然后 leader 接收客户端的 log entries，复制给其他 servers，并告诉它们什么时候可以把 log entries 应用到它们的状态机。\nRaft 协议把共识算法分解成三个互相无依赖的子问题：\nLeader election：当现有的 leader 失效后，必须选举出新 leader Log replication：leader 从客户端接收 log entries，并复制到集群的其他 servers 上 Safety：如果一个 server 把某个 log entry 应用到它的状态机，则集群其他 server 与此 log entry 相同的 log index 上，使用的都是同一个 log entry. Raft 详细内容 所有服务器的持久状态（persistent state）： currentTerm: 服务器上次看到的 term votedFor: 当前 term 收到投票的服务器ID，如果没有，是 null log[]: log entries，从 leader 接收到的每个 entry 都包含状态机的命令，和当时的 term 所有服务器的不稳定状态 （volatile state）： commitIndex: 已知需要提交的最高 log 的 index lastApplied: 已经应用到状态机的最高 log 的 index leader 服务器的不稳定状态（选举后重新初始化） nextIndex[] 需要发送给特定 server 的下一个 entry 的 index（初始化为 leader last log index + 1） matchIndex[] 已知在每个 server 上已复制的 index AppendEntries Rpc leader 调用用来备份 entries；同时也是用来作为心跳的 rpc 参数：\nterm: leader 的 term leaderId: follower 可以据此重定向 client 的请求 entries[]: 同步的命令，可以为空 prevLogIndex: entries 前一个 entry 的索引 prevLogTerm: prevLogIndex 的 term leaderCommit leader 的提交索引 响应：\nterm：接收端 currentTerm，leader 可以根据响应更新自己的状态。（比如 leader 落后 term，变为 follower） success: 如果 follower 包含对应的 prevLogIndex 和 prevLogTerm，则是 true 接收端实现：\n如果 term \u0026lt; currentTerm，return false 如果 prevLogIndex， prevLogTerm 不存在，则 return false 如果已存在的 entry 与 new entries 冲突（相同 index，不同 term），删除现有的 entry，使用 leader 的 entries 新的 entries 全部 append 到 log 中 如果 leaderCommit \u0026gt; commitIndex, 把 commitIndex 设置为 min(leaderCommit, index of last new entry) RequestVote Rpc 候选人调用，获取选票。\n参数：\nterm: 候选人的 term candidateId: 候选人id lastLogIndex: 候选人最后一条 log entry 的 index lastLogTerm: 候选人最后一条 log entry 的 term 响应：\nterm: currentTerm，候选人根据此 term 更新自己 voteGanted: 为 true 表示候选人得到了选票 接收端实现：\n如果 term \u0026lt; currentTerm，则 return false 如果 votedFor 是 null 或者 candidateId，且候选人日志至少是最新的（比投票人的 lastLogIndex 更新或相同），投票为 true Servers 的规则 All Servers:\n如果 commitIndex \u0026gt; lastApplied，增加 lastApplied，并把 log[lastApplied] 应用到状态机 如果 RPC 请求或响应存在 term T \u0026gt; currentTerm，设置 currentTerm = T，并设置为 follower Followers:\n响应 candidate 和 leader 的 rpc 调用 如果选举超时结束，且没有收到 leader 的 AppendEntries RPC 和 candidate 的 RequestVote RPC，则变为 candidate Candidate:\n当变为 candidate 后，开始选举 增加 currentTerm 投票给自己 重设 election timer 向其他 server 发送 RequestVoteRpc 如果收到大多数 server 的选票，变为 leader 如果收到新 leader 的 AppendEntries RPC，则变为 follower election timer 超时，重新开启选举 Leader:\n选举时，发送空 AppendEntriesRPC 到每个 server；空闲期间重复发送，避免选举超时 收到 client 的命令后：把 entry 追加到本地 log，当 entry 被应用状态机后返回 如果 follower 的 last log index \u0026gt;= nextIndex，AppendEntryRpc 的 entries 从 nextIndex 开始发送 如果 success，更新记录 follower 的 nextIndex 和 matchIndex 如果 fail，减小 nextIndex，并重试 如果存在 N， N \u0026gt; commitIndex，且大多数的 matchIndex[i] \u0026gt;= N, 且 log[N].term == currentTerm，set commitIndex = N 安全性保证 通过以上逻辑，Raft 可以实现下面的安全性保证。\n选举安全：每个 term 只能有一个 leader 被选举出来。\nLeader 日志仅追加（Append-Only）: leader 不会修改或删除它的本地 Log，仅追加。\n日志匹配（Log Matching）: 如果两个 logs 有相同的 index 和 term，则这两个 logs 里所有的 entry 都是相同的。\nLeader 完备（Leader Completeness）: 如果在特定 term 提交了一个 entry，则在所有更高 term 的 leader 里，它都是存在的。\n状态机安全：如果一个 server 已经 apply a entry 到状态机，则相同的 index 下，其他 server apply 的是同一个 entry。\nLeader 只会通过计数本任期 term 下产生的 entry 的备份数量，来提交 entry（设置 commitIndex）。\n其他 时间与可用性：广播时间 \u0026laquo; 选举超时时间 \u0026laquo; 崩溃间隔。内网广播时间（请求响应一来一回的时间）通常是几毫秒内；崩溃间隔通常几天、几月甚至更长。选举超时时间一般随机设置在 150ms - 300ms，太长会影响 leader 崩溃后系统的恢复速度，太短则可能频发引发选举。\n集群成员改变（增减）：使用 config log entry 同步成员信息，保证配置信息共识。成员初次加入需要同步数据，同步数据时没有投票权，不占大多数计算逻辑；直到追上日志后才能投票。\n日志压缩：快照模式，各个 server 管理自己的快照。快照后，前面的 log entries 可以删除。如果 leader 给 follower 需要同步的日志已删除，需要接口先同步快照，再同步后面的日志。同步快照使用 InstallSnapshot RPC。\n客户端交互：客户端随机选择节点发起请求，如果是 follower 节点，则节点拒绝请求，并返回 leader 信息。客户端向 leader 发起请求。\n为了避免 leader 已提交但未响应 client 后崩溃，client 重新请求新 leader 节点会导致命令多次执行，每个 command 需要带一个唯一标识，新 leader 包含所有已提交 entry，遇到相同的唯一标识的 command，直接返回已执行即可。\nhttps://raft.github.io/raft.pdf Diego Ongaro and John Ousterhout Stanford University\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttp://thesecretlivesofdata.com/raft/ Raft: Understandable Distributed Consensus\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"Mar 01","permalink":"https://xiang-xx.github.io/posts/raft-protocol/","tags":["阅读"],"title":"Raft 协议核心内容"},{"categories":null,"contents":" 前言 互联网企业里或多或少都会有些数据密集型系统，比如一家互联网教育企业，付费用户虽然不多，但视频观看打点频率高，观看日志的数据量可以很大；一个在线聊天软件，用户聊天数据也会快速增长。《设计数据密集型应用》1一书内容丰富，涵盖了数据系统存储细节、分布式、数据一致性等问题，由浅入深，由底层细节到顶层架构，循序渐进地展开一张数据密集型系统的画卷全貌。\n可靠性、可伸缩性和可维护性 与数据密集型系统对应的是计算密集型系统。在互联网行业中，更常见的是数据密集型系统。此书的目标是介绍如何打造可靠、可伸缩、可维护的数据系统。\n可靠性：系统在困境中（硬件故障、软件故障、人为错误）仍可以正常工作 可伸缩性：有合理的办法应对系统的增长（数据量，流量，复杂性） 可维护性：许多不同的人，在不同的声明周期，都能高效的在系统上工作 提高可靠性：\n硬件：提高冗余度 软件：彻底的测试、进程隔离、允许崩溃重启、测量/监控/自检/报警等 人为错误：沙箱环境、只读环境、允许快速回滚、允许数据重算、API 限制、管理后台、人员培训等（最小化犯错误机制，允许犯错并修复，监控错误产生） 性能：批处理关注吞吐量，在线服务系统关注响应时间。\n通常使用响应时间的高位百分比描述服务性能。比如: 50%的响应小于200ms，99% 的响应时间小于 1s，即 p50\u0026lt;100ms, p99\u0026lt;1s。\n可伸缩性：纵向伸缩（scaling up），横向伸缩（scaling out）。\n可维护性与软件系统设计的原则：\n可操作性：便于（运维团队）维护系统平稳运行 简单性：从系统中尽可能消除复杂度。减少系统状态、降低模块耦合、理清依赖关系、术语命名一致\u0026hellip; 可演化性（可扩展性，可塑性） 数据模型与查询语言 常见的数据模型：\n网状模型（CODASQL 为例）：数据库存在模式；访问特定记录需要遍历其中一条路径；查询是命令式，难以编写和维护 关系型：写时模式（schema-on-write）；范式设计导致从数据到代码对象需要复杂的转化；能够更好的处理多对多的关系；查询时通常需要遍历更多的数据 文档型：读时模式（schema-on-read）；代码查询简单；文档引用技术解决多对多的关系；查询局部性相对好；更新文档通常需要整个重写。 图模型：更适合多对多的关系；顶点和边不仅限于一种类型，顶点可以表示人、地点、事件，边可以表示哪些人彼此是好友、谁参与了哪个事件；适用于社交图谱，网络图谱，公路铁路网络等。 其他：用于基因相似性检测的搜索引擎（序列相似性搜索）；全文搜索；PB级大数据存储模型。 声明式查询语言（SQL，mongo，es）：简单容易；隐藏了数据库细节，便于兼容前后版本；适合并行查询。\n命令式查询语言（例如 CODASQL）：类似编程语言的执行逻辑。\nMapReduce 介于声明式和命令式之间，使用代码逻辑编写，但能够并行在多台机器上分布式执行。\n存储与检索 存储引擎的两个大类\n日志结构（log-structured） 面向页面（page-oriented） 日志结构存储引擎通常是追加写，在机械硬盘上性能较好，崩溃恢复简单，日志文件分段，删除使用特殊的标记，段文件可以后台合并，单独一个写线程避免并发问题。\n日志结构的散列索引：范围查询性能很低；必须能够放在内存里，否则磁盘映射性能很低。\nSSTable 排序字符串表，LSM（日志文件合并树）：\n每个段文件内 key 是有序的 多个段文件合并后按照 key 的顺序写入到新段文件 当前段文件使用有序结构（红黑树等）维护在内存中，磁盘维护当前分段的顺序写日志；达到一定阈值，写入新段文件，删除旧的顺序写日志 使用 bloom 过滤器，优化不存在的 key 的查找 有序 key 可以加快范围查询 面向页面结构的存储引擎通常使用 B 树及其变体作为存储引擎。 B 树将数据库分解成固定大小的块或页，一次性只能读取或写入一个页面；这种设计接近底层页面，因为磁盘空间也是按照固定大小组织的 页面之间使用地址（硬盘地址，而非内存地址）互相引用，构建出树 一个页面的引用数量称为分支因子，通常是几百（分支因子为 500 的 4KB 页面的四层树可以存储 256T 数据） 使用预写日志（WAL，或重做日志 redo log，追加写文件）实现崩溃恢复 使用锁控制页面写入 如果一个页满了，则分裂成两个半页 B 树相关优化：\n字符串 key 可以不存储整个键，缩短键大小以增大分支因子 写时复制，经过修改的页面写入到不同位置，便于并发控制和崩溃恢复 使叶子页面尽量放在相同的位置 额外的指针，使用每个叶子页面可以连接左右兄弟页面，顺序扫描不需要跳回父级 分形树（fractal tree）2，在节点上缓存变更操作，接用日志结构的思想减少磁盘查找 数据仓库的列式存储（在线分析处理 OLAP）：\n每个列存储在单独的文件，所有列包含的行的顺序是对应的，可以通过列构建出行 数仓事实表的列通常很多，数据分析时只关心若干列，没必要把其他列读出来 列数据存储在一起便于压缩，比如有些列只有若干可能的值，通过位图编码可以极大压缩；列排序后对于压缩更友好 使用 LSM，分批次写入数据，降低大量数据写入的瓶颈 物化视图，对于 count、sum、svg、max 等数据物化存储，便于查询 编码和演化 常用的文本格式编码：json，xml，csv；易读，但数据量相对大；二进制编码：protobuf，thrift；数据量通常能压缩 20% 以上，缺点是不可读；编程语言特定的编码仅限于单一语言，通常不使用。\n复制 主从模式是比较常见的模式模式。Mysql、redis、PostgreSQL、kafka 等都是用主从模式。\n同步复制：主库等待从库复制完成再响应请求。能够保证从库与主库数据一致，主库不可用时，从库包含完整的数据。但如果从库故障，主库也无法写入。\n半同步：一个从库使用同步复制，其他从库是异步的。确保有一个从库是同步复制的。\n异步复制：主库的写入不能保证持久。\n复制的实现：\n基于语句的复制：使用非确定性的语句、函数，以及现有数据不一致时，可能导致语句在从库上产生的效果不同。 基于预写日志复制（WAL）：预写日志通常涉及到底层存储，比如覆写某个磁盘页，不同版本之间可能不兼容。 基于行的逻辑日志复制（例如 binlog）：将复制日志从存储引擎中解耦出来，且对于外部来说，逻辑日志更容易解析，便于发送到外部系统中处理 基于触发器的复制：灵活性强，但开销比较高。 异步复制因为网络延迟的存在，只提供最终一致性。\n读己之写：用户提交完数据想要立刻查看，则新数据未到达副本，可能导致未查到，像是数据丢失。确保写后读一致性的一些方式：\n对于用户可能修改过的数据，总是从主库读。比如用户读取自己的个人信息走主库，读取其他人的信息走从库 如果应用的大部分内容都可能被用户编辑，则可以跟踪上次更新时间来决定是否读从库。还可以监控从库延迟 客户端可以记录最后一次写入的 逻辑时间戳，据此判断是否读从库 如果副本分布在不同地理位置的数据中心，则更复杂。任何需要主库提供服务的请求，都需要被路由到主库所在的数据中心 单调读：确保每个用户总是从一个副本读取，避免来回切换延迟时间不同的副本，导致读的数据一会儿有一会儿没有。\n一致前缀读：具有因果关系的一系列数据写入后，读取这些数据也必须按照相同的顺序出现。比如 A，B 两个有因果关系的事件先后写入数据库后，用户读从库的时候不能只读到 B 但没有读到 A。通常在分片或分区数据库中会出现这种场景，需要确保具有因果关系的事件写入到相同分区。\n多主复制的使用场景：\n运维多个数据中心，数据就近访问，降低地理位置导致的延迟 需要离线处理的客户端，比如印象笔记 协同编辑 多主复制最大的问题是写入冲突。\n避免冲突：对相同记录的操作路由到同一个数据中心 收敛至一致的状态：每个写分配一个 ID，冲突时 ID 大的覆盖小的（数据丢失）；以某种方式把值合并在一起；编写解决冲突的代码。 多主复制的一些拓扑： 无主复制：客户端直接将写入发送到多个副本（通常会有个协调者节点，代替客户端写入，节点之间没有固定写入顺序）。无主复制处理节点数据不一致方案：\n读修复：读取时，修复陈旧的节点数据（冷数据可能用于读不到，不会修复） 反熵过程：后台进程不断查找副本差异，修复数据 读写的法定人数：假设有 n 和副本，w 个副本确认表示写入成功，读取时需要从 r 个副本读取\n需要确保 w+r \u0026gt; n，这样读的副本里至少有一个是最新的 通常 w = r = (n+1)/2 w 越大，r 越小；则 读取效率高，写入效率低，适合读多写少的系统； 检测并发写入：多个客户端可以同时对一个 key 写入，但写操作可能按照不同顺序到达不同节点。并发写入规避方案：\nLWW 最后写入胜利：每个请求加一个时间戳，大的覆盖小的 一个键只允许写入一次，不允许更新 写入前先读取，读取值包含版本号，写入时传入版本号，只能覆盖相同或更低的版本号 使用客户端程序合并写入 版本向量：对于一个键值，所有副本的版本号的集合成为版本向量，读取值时，版本向量会发送给客户端，写入时需要传给数据库。版本向量允许数据库区分覆盖写入和并发写入。 分区 分区通常和复制同时使用，每个分区的副本存储在多个节点上。如果分区是不公平的，则一些分区比其他分区有更多的数据和查询，产生数据偏斜，导致分区效率下降。\n根据键的范围分区。例如百科全书按照关键字的分区。分区边界可以由管理员手动选择，也可以由数据库自动选择。Bigtable/HBase 使用类似方法。优点是存在顺序性，便于范围查找；但容易造成数据倾斜。比如键中带有时间戳 \u0026ndash; 可以在时间戳前面加上其他的字段。\n根据键的散列分区。好的散列函数可以把键均匀分布，但范围查询效率低。\nCassandra 的折衷策略：主键采用多个列组成，第一个列用作 hash 分区，后续键使用 SSTables 排序；如果指定了第一个键查询，则后续的键可以范围查找。\n负载偏斜与热点消除：极端情况下，某些键会被大量的读取写入，比如热点微博的数据；这种热点数据或造成分区的负载偏斜。解决方案：使用一定策略，判断这些键需要被额外分区，比如后面加上后缀，{id}_0,{id}_1\u0026hellip; 把热点数据分成若干份，存储在不同分区，读取的时候再进行合并。\n基于文档的次级索引进行分区。即每个分区维护自己分区内文档的次级索引，查询的时候并发从各个分区查询；这种方案比较简单，但并发多条查询容易导致尾部延迟放大。\n基于关键词（term）的次级索引进行分区。构建覆盖所有分区数据的全局索引，全局索引也需要分区，可以采用与主键不同的分区方式。 关键词分区；关键词（term）源自全文搜索引擎，指文档中出现的所有单词。这种次级索引分区方式写入速度慢，且比较复杂；在实践中，对全局索引的更新通常是异步的。\n分区再平衡策略：\n反面教材：hash mod n，导致再平衡发生时大量数需要移动 固定数量的分区：分区数量比节点数量多，比如 5个节点，100 个分区，如果一个节点挂了，则另外四个节点均分挂掉的 20 个分区。 Riak/ES/CouchBase/Voldemort 都使用这种策略 动态分区：分区增长到一定大小时，会被分成两个分区，各拥有一半数据；如果大量数据删除，分区变小，则可以合并分区。动态分区同时支持 hash 分区和范围分区。 HBase/MongoDB 按节点比例分区：分区数与节点数成正比，即每个节点具有固定数量的分区，通常每个节点的分区数比较多，以保证数据的平衡。Cassandra 中，每个节点默认 256 个分区。 分区请求路由方式：\n允许客户连接任何节点（通过循环策略的负载均衡，Round-Robin Load Balancer），如果节点有请求的分区，则直接处理请求；否则，它转发到其他节点，收到回复并返回给客户端 将客户的请求发送到路由层，它决定应该处理请求的节点，并进行转发 要求客户端知道分区和节点的分配 事务 事务的 ACID：\n原子性（Atomicity）：能够在错误时中止事务，丢弃该事务的所有写入变更的能力 一致性（Consistency）：对数据的一组特定约束始终不变 隔离性（Isolation）：同时执行的事务是相互隔离的。 持久性（Durability）：持久性是一个承诺，即一旦事务完成，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。完美的持久性是不存在的。 非事务的 BASE：\n基本可用性（Basically Available） 软状态（Soft State） 最终一致性（Eventual Consistency） 对于应用而言，没有事务，错误处理复杂很多；没有隔离性，就会导致并发问题。\n可串行化的隔离级别保证事务的执行效果如同串行发生；会有严重的性能损失，一般数据库不使用。一般事务只使用弱的隔离级别。\n读已提交：提供了两个保证\n从数据库读时，只能看到已提交的数据，没有脏读 写入数据库时，只能看到已提交的数据，没有脏写 数据库使用 行锁 来防止脏写（两阶段锁协议）\n快照隔离 和 可重复读：一些情况下无法容忍同一个事务多次读的数据不一致（或一致性遭破坏）\n备份；如果备份了一部分新 一部分旧的数据，会破坏一致性 分析查询和完整性查询：需要扫描大量的数据，不一致的数据可能导致完整性损坏 快照隔离的实现：\n使用写锁防止脏写 读取不需要加锁，性能方面：读不阻塞写，写不阻塞读 多版本并发控制（MVCC）：维护单个对象的多个版本，mysql 使用 undolog 实现访问旧版本；读已提交为每个查询使用单独的快照；可重复读（快照隔离）对整个事务使用相同的快照 每一行都有 created_by 和 deleted_by 字段，存储它被创建，被删除的事务ID update 操作在内部被翻译成 delete 和 insert 操作 事务 ID 决定了它能看到哪些对象：\n每次事务开始时，数据库列出当时其他（尚未提交或尚未中止）的事务清单，即使后续提交了，这些事务已执行的任何写入也都会被忽略 被终止事务写入的任何执行都会被忽略 有具有较晚事务的事务ID所作的任何写入都会被忽略 所有其他写入，对应用是可见的 防止丢失更新的场景与办法：（事务执行顺序为 读 - 修改 - 写入序列，可能导致写入互相覆盖，丢失更新数据）\n原子写： update x set val = val +1 where y=b; 显式锁定：select * from xx where a = b for update; 自动检测丢失的更新：postgresql 的可重复读会自动检测丢失更新，并中止惹麻烦的事务；mysql 的 Innodb 不会。一些人认为能够自动检测丢失的跟更新才称得上是快照隔离 CAS，比较并设置，update x set val=val2 where id=1 and val=valold; 写入偏差与幻读：案例：select count(*) from xx where a=b; 当 count \u0026gt; 2 时，写入一条新的 a=b 的数据；并发写入时，破坏了 count \u0026gt; 2 的约束条件。解决办法：\n使用 select for update，显式锁定 物化冲突。人为地在数据库中引入一组对象，用作锁。比如会议室预定的场景下，可以床架一个时间槽和房间槽的表，写入预定记录之间先使用 select for update 锁定槽位。 可串行化有多种实现方案：单一线程顺序执行事务（性能低）、两阶段锁定、可串行化快照隔离。\n可串行化的两阶段锁定：读会阻塞写，写会阻塞读；事务提交后释放锁；悲观锁，性能差。\n可串行化的快照隔离方案：乐观锁；事务写入数据库时，必须在索引中查找最近读取的受影响数据的其他事务，如果数据已不是最新的，则中止事务。\n分布式系统的麻烦 分布式系统中容易发生部分失效（以某种不可知的方式被破坏）。部分失效是不确定性的：任何涉及到多个节点和网络的事情，它有可能会工作，有时会出现不可预知的失败。\n不可靠的网络：当发出请求并期待响应，可能在任何节点任何阶段出错。处理这个问题的常用方法是超时。\n不可靠的时钟。NTP 网络时间协议。它允许根据一组服务器报告的时间调整自己的时间。\n日历时钟：根据某个日历返回当前的时间，比如 unix 时间戳。日历时钟经常与 NTP 同步，可能导致时间回溯的情况。 单调时钟：它保证时间总是向前走的，适合测量持续时间（例如时间间隔），NTP 同步时，如果过快，则向前走的频率可以调低 0.05%，如果过慢，则可以调快 0.05%。单调钟可以是系统启动后的纳秒数。 逻辑时钟，使用递增计数器，而不是石英振荡器。 真相由多数定义，通过投票以减少对某个特定节点的依赖。\n一个 gc 导致锁失效，但代码继续执行覆盖了后续写入数据的案例： 使用递增 token；比如使用 zookeeper 作为锁服务，可以使用 txid 或者节点的 cversion 作为令牌，因为它保证单调递增。\n拜占庭故障：有些节点可能因为延迟或其他原因，有意或无意发出错误消息 \u0026ndash; 比如告知没有收到某条写请求。当一个系统中部分节点出现故障、不遵守协议、甚至恶意攻击、扰乱网络时仍能正常工作，称为拜占庭容错。常见系统：飞行控制系统，区块链系统。\n弱谎言形式：假定节点不会故意撒谎，使用防止撒谎的弱形式机制，比如：\n网络系统中的校验和，检测可能因为硬件或其他问题导致数据包损坏 校验用户的输入合法性 使用加权平均作为从多个分布式系统中同步的值，比如 币价/NTP时间 安全性：安全性被违反后，违规行为不能被撤销 \u0026ndash; 损失已经发生。比如 唯一性和单调序列属于安全性，如果产生了重复值，则系统损失已经发生，这个动作也不会恢复。活性：活性被破坏后，未来可能恢复，比如可用性，如果出现节点故障，暂时不可用，但未来也会是可用的。包括 最终一致性，也属于活性。\n算法的正确性建立在我们假设的系统之上，比如我们假设拜占庭故障节点数量低，所以算法才能成立，我们假定节点存储的数据不丢失，才能保证法定人数算法能够正确。 而现实世界可能会发生各种情况打破假设。 证明算法正确并不意味着它在真实系统中一定正确。\n一致性与共识 大多数复制的数据库至少提供了最终一致性。\n线性一致性：数据库提供只有一个数据副本的假象，多个客户端在任何时候读取的数据，都能在某个时间点变更后，读到新数据。\n依赖线性一致性的场景：\n锁定和领导选举；如果违反线性一致性，则可能出现脑裂 约束和唯一性保证 跨信道的时序依赖：比如上传完图片后，发送图片 url 到消息队列，异步任务处理消息获取 url 对应图片并处理，结果图片还未同步到其他节点，访问不到图片，或访问的是旧图片 CAP 定理：\n网络分区是一种故障类型，所以它并不是一个选项：它一定会发生 如果需要线性一致性，则发生副本掉线时，系统需要等待，期间不可用 如果应用不需要线性一致性，则某个副本断开后，也可以独立处理请求 顺序保证了线性一致性，线性一致性包含了因果一致性。线性顺序是全序的，表现为系统中好像只有一个副本，而因果关系是偏序的，存在因果的两个事件是有序的，无因果关系的事件无序。线性一致性强于因果一致性。一个系统可以是因果一致的，而避免线性一致性带来的性能损耗。\n为了确定因果顺序，数据库需要知道应用读取了那个版本的数据：\n比如写操作需要传入之前读操作得到的数据版本号 可串行化隔离快照中，数据库检查它读取的版本是否依然是最新的 兰伯特时间戳：由（计数器，节点ID）组成；计数器更大，时间戳更大；计数器相同，节点ID大的更大。 全序广播满足两个安全属性：\n可靠交付：没有消息丢失，如果消息被传递到一个节点上，它将被传递到所有节点 全序交付：消息以相同的顺序传递到每个节点 全序广播的重要表现：顺序在消息送达时被固化，如果后续的消息已经送达，节点就不允许追溯地将之前的消息插入顺序中较早位置。（解决了并发覆盖写导致数据不一致问题）\n使用全序广播实现线性一致性存储。使用仅追加日志的方式实现这种 CAS 操作：\n在日志中追加一条消息，并试探性的指明你想要的用户名 读日志，并等待你刚才追加的消息被读回 检查是否有任何消息生成目标用户名的所有权，如果第一条是你的消息，则操作成功，你可以提交声称的用户名并向客户端确认。如果第一条消息来自其他用户，则中止操作。 使用全序广播实现读取线性一致性的方案：\n可以先向日志中追加一条消息，直到消息被读回，才执行实际操作 \u0026ndash; 此时说明读之前的消息已全部同步 查询最新消息的位置（如果允许的话），直到同步到此位置，再进行读取操作 从同步更新的副本中读取 两阶段提交使用一个通常不会出现在节点上的新组件：协调者（也叫事务管理器） \u0026ndash; 它可能是客户端上的一个库，或一个进程，或一个单独的服务。协调者向所有参与者（节点）发送 prepare 请求：\n如果所有参与者都回答“是”，则协调者在第二阶段发出 commit 请求 如果任一参与者回答“否”，则协调者在第二阶段发出 abort 请求 系统承诺：\n事务ID全局唯一 在参与者单节点事务上带上此事务ID 当应用准备提交，协调者向所有参与者发送 准备 请求，并打上全局事务ID 的标记。如果任一请求失败或超时，则协调者向所有参与者发送针对此事务ID的中止请求 参与者收到准备请求时，如果回答 是，则参与者需要确保只要请求，就一定能够提交 当协调者收到所有答复时，会对是否提交事务做出决定；协调者必须把决定写到磁盘的事务日志中，如果随后崩溃恢复，也能够知道自己做出的决定。这被称为提交点 一旦协调者的决定落盘，提交或放弃请求会发送给所有参与者。如果请求失败或超时，则必须一直重试下去 协调者失效时，如果刚好有事务执行完第一阶段，未收到第二阶段的参与者节点会一直处于 存疑 状态，直到协调者回复。存疑时会一直持有锁，直到事务提交或中止。\n共识问题通常形式化如下：一个或多个节点可以提议（propose），而共识算法决定（decides）。共识算法必须满足以下性质：\n一致同意：没有两个节点的决定不同 完整性：没有节点决定两次 有效性：如果一个节点决定了值 v，则 v 由某个节点所倡议 终止：由所有未崩溃的节点来最终决定值 纪元编号与法定人数（raft 协议3）\n协定定义了一个纪元编号，并确保每个时代中，领导者都是唯一的 纪元编号是递增的，领导者被认为挂掉后，需要重新投票；两个不同时代的领导者之间出现冲突，更高纪元编号的说了算 必须从 法定人数 的节点中获取选票 两轮投票：第一次是为了选出领导者；第二次是对选出的领导者进行表决（类似两阶段提交）；这两次投票的法定人群必须相互重叠（即要求法定人数 \u0026gt; n/2） 批处理 一个 MapReduce 作业和一个 Unix 进程相类比：它接收一个或多个输入，并产生一个或多个输出。MapReduce 在分布式系统上读写文件 \u0026ndash; HDFS Hadoop 分布式文件系统。\nHDFS 在每台机器上运行了一个守护进程，它对外暴露网络服务，允许其他节点访问存储在该机器上的文件。名为 NameNode 的中央服务器会跟踪那个文件块存储在哪个机器上。为了容忍机器和硬盘故障，文件被复制到多台机器上。\nMapReduce 基本工作流程：输入格式解析器处理输入；Mapper 函数提取键值对；输出数据到 Reducer 时会自动按照键值对排序；Reducer 处理每个键的所有值。\nMapper：Mapper 会在每条输入记录上调用一次，从每条输入记录上提取键值。对于每个输入可以生成任意数量的键值对，包括 None。无状态，每条记录是独立的。\nReducer：MapReduce 框架拉取由 Map 生成的键值对，收集属于同一个键的所有值，并在这组值上迭代调用 Reducer。Reducer 可以产生输出记录。\n将计算放在数据附近：每个输入文件的大小通常是几百兆，MapReduce 调度器试图在每台存储输入文件副本的机器上运行每个 Mapper。节省了网络复制输入文件的开销。\n流处理 在流处理中，一个事件由生产者产生一次，然后可能由多个消费者处理。相关的事件通常被聚合成一个主题（topic）或流（stream）。\n消息传递系统的方案：\n直接从生产者传递给消费者：UDP、无代理的消息库 ZeroMQ nanomsg 等、通过 http 或者 rpc 传递给消费者（webhook） 消息代理：kafka、redis等 消息代理：\n通常 消息传递给消费者后会自动删除（或保存一段时间后删除） 队列工作集比较小，比如 kafka 默认保存 7 天 支持按照某种模式匹配主题，订阅其子集 不支持任何查询，通常只能流式订阅 多个消费者从同一主题读取消息的模式：负载均衡，每个消息被传递给消费者之一；扇出（fan-out），每个消息被传递给所有消费者。\n确认与重新传递：客户端显式告知消息代理 消息已经处理完毕。\n分区日志：基于日志的消息代理。对日志进行分区，存储在不同的机器上；每个分区内，消息被分配一个单调递增的序列号（或偏移量）。记录消费者消费某个分区消息的进度，称为消费者偏移量。\n当消费者跟不上生产者时：丢弃消息、进行缓冲、施加背压，影响生产者的速度。可以监控消费者落后日志头部的距离，落后太多就发出报警。\n保持多系统数据同步的方式：\n双写：比如写入数据库时，同时写入数据库和缓存/ES。但并发写入到每个系统的时间不一致，发生冲突导致系统数据不一致 变更数据捕获（CDC）：捕获数据库的变更日志，通过消息代理给多个系统消费，同步数据 系统变更事件是不可变的，所以可以从事件日志派生出当前状态。\n流处理的一些场景：\n复合事件处理 流分析，例如 prometheus（滚动计算、区间对比统计、测试事件速率） 维护物化视图：缓存，搜索索引，数据仓库 在流上搜索：先构建搜索查询，再在流数据上跑查询 消息传递和 rpc 流分析的时间窗口类型：\n滚动窗口：每个事件只能属于一个窗口，比如 一分钟一个窗口 跳动窗口：固定长度，但允许窗口部分重叠，例如：一个步长为 1 的，长度为 5 的跳动窗口 滑动窗口：跟跳动相比，没有步长的概念，不断往窗口添加新数据，移除旧数据 会话窗口：没有固定持续时间，将一个用户出现时间相近的事件联系在一起 流流连接：在处理流数据时，需要额外的数据库存储流事件，以便另一个事件到达后能够查询到此事件。 流表连接：创建事件时，把数据库副本数据写入到事件里，这样处理事件时不用查询数据库；或者处理事件时查询数据库。\n流处理中的容错手段：微批次和存档点、使用事务原子提交、幂等性、失败后重建状态。\n数据系统的未来 组合使用衍生数据的工具，比如搜索引擎/缓存/分析型数据库。分布式事务性能较低，容错能力差，但提供线性一致性，读己之写；衍生数据通常是异步的，提供最终一致性。\n组合使用数据库存储技术：次级索引、物化视图、复制日志、全文搜索引擎。\n联合数据库：统一读取。为各种各样的底层存储引擎和处理方法提供统一的查询接口；例如 PostgreSQL 的外部数据包装器。分拆数据库：统一写入；变更日志捕获衍生到其他系统。\n将事情做正确：\n端到端原则：只有在通信系统两端应用的知识和帮助下，所讨论的功能才能完全正确的实现。比如 tcp 两端需要记录维护序列号；比如幂等操作需要两端都保证唯一标识符。 强制约束。唯一性约束需要达成共识：最常见的方式是使用单节点作为领导，负责所有决策；全序广播；分区依赖消息日志进行处理。 及时性与完整性。事务通常提供一致性：一致性实际包含 及时性（线性一致性，读己之写）和完整性。 信任但验证。不要盲目信任承诺。审计，审查数据完整性。 做正确的事情：预测性分析可能存在的偏见与歧视，推荐系统的责任问题，反馈循环功能。隐私与追踪需要符合法律法规，防止用户数据滥用，允许用户选择是否同意上传个人数据等。\n《Designing Data-Intensive Applications》Martin Kleppmann. 中文翻译 http://ddia.vonng.com/ 冯若航 （@Vonng）\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n分形树 https://en.wikipedia.org/wiki/Fractal_tree_index\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nraft 协议动画演示 http://thesecretlivesofdata.com/raft/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"Feb 25","permalink":"https://xiang-xx.github.io/posts/read-ddia/","tags":["阅读"],"title":"读《设计数据密集型应用》"},{"categories":null,"contents":" 前言 《计算机程序的构造和解释》（Structure and Interpretation of Computer Programs、SICP）1，也称 SICP，是麻省理工学院（MIT）计算机科学的入门教材。书中以 Scheme 语言为例（Lisp - List Processing 语言的一种方言），通过大量代码案例，详细介绍了程序如何抽象构造出来，以及程序解释/编译/运行的基本流程。对于日常使用高级语言的工程师来说，阅读此书能够对程序底层运行过程有一定的理解。\n编程语言的抽象 编程语言提供一些基础元素，比如基本类型，运算符，关键字等，并使用表达式构建成语句，语句通过一系列的方式构成 复合过程（函数，方法，闭包，lambda 等）。\n一个问题的求解过程通常可以有很多种，比如计算阶乘，可以用简单的递归算法：\n1 2 3 4 5 6 func factorial(n int) int { if n == 1 { return 1 } return n * factorial(n-1) } 此算法的计算过程：先展开，后归约，比如计算 factorial(4)，展开与规约的过程：\n4 * f(3) 4 * 3 * f(2) 4 * 3 * 2 * f(1) 4 * 3 * 2 * 1 4 * 3 * 2 4 * 6 24 如果使用迭代的方式计算：\n1 2 3 4 5 6 7 8 func factorial(n int) int { a := 1 for n \u0026gt; 0 { a = a * n n -= 1 } return a } 其计算过程因为没有先展开后规约的过程，所以看上去简洁很多：\na = 4 n = 4 a = 12 n = 3 a = 24 n = 2 a = 24 n = 1 书中还提到计算 n 的 k 次方的算法（k \u0026gt; 0）。最直观的解法是递归求 f(n, k) = n * f(n, k-1)。次方问题可以根据 k 的奇偶进行划分：\nn 是偶数：f(n, k) = f(n*n, k/2) n 是奇数：f(n, k) = n * f(n, k-1) 根据上述公式，可以很简单的实现出递归程序，时间复杂度是 O(logk)；在不考虑尾递归优化的情况下，递归使用了额外栈空间，所以空间复杂度也是O(logk)。你可以试着把递归改成迭代形式，以降低空间复杂度。\nLisp 跟如今的一些高级语言一样，也把函数作为一等公民。函数可以赋值给变量，可以作为参数，可以作为返回值。\n闭包跟普通函数的不同点在于闭包携带的执行环境。执行环境由两部分组成：用于记录环境内变量的表格，和指向外围环境的指针。任何过程在执行时都会有一个执行环境，过程中用到的变量的值，需要从执行环境中查找，如果当前执行环境没有，则向外围环境查找，直到找到，或者外围环境为 nil 为止。\n过程的执行环境是在其创建时决定的，比如一个定义在全局的函数，他的执行环境就是全局共用的 global 环境；一个闭包在函数内创建时，会给它创建一个新的局部环境 \u0026ndash; 表格里记录局部环境的变量，指针指向创建它的函数的环境（可能是 global 或者另外一个局部环境）。\n模块化，状态 这是一个带有状态的闭包实现：\n1 2 3 4 5 6 7 8 9 10 func newWithdraw() func(int) int { amount := 100 return func(a int) int { amount -= a return amount } } w := newWithdraw() println(w(10)) println(w(20)) 闭包使用局部环境维护了局部状态；同时局部状态隐藏在闭包内部，实现了模块化。但这种方式会导致内部不透明，且构造出的闭包不是同一的，无法互相替代。\n不需要任何赋值操作的设计，成为函数式程序设计，函数式程序设计没有状态修改。与之相反的是命令式程序设计。以求 n 的 k 次方的为例（Ologn 解法），使用递归函数的程序设计简单直观，不容易出错，使用迭代赋值，维护当前状态的命令式函数设计，会导致计算模型更复杂，更容易出错。\n并发的问题 lisp 使用互斥锁 mutex 实现串行化组来规避并发问题，使用 test-and-set 判断 mutex 是否可用，test-and-set 使用处理器提供的原子指令。\n死锁案例：两个进程同时修改若干账户的余额，修改每个账户的余额需要先获得该账户的锁，每个进程必须持有全部锁后才能修改完成，并释放锁。这种场景下，可以通过给账户唯一编号，然后按照编号顺序进行锁定，避免死锁发生。\n某些场景无法避免死锁，比如需要先获取到 A账户的锁，根据余额情况再决定锁哪些账户。\n元循环求值器 元循环求值器是指使用自身语言实现的自身代码的求值器。以 lisp 来说，就是用 lisp 写一段程序，这段程序的输入是一段 lisp 程序，并求出这段程序的运行结果。\n求值器的核心函数：eval(exp, env), exp 是程序过程，env 是执行环境。eval 返回 exp 在 env 环境下的运行结果。Lisp 语法简单，所以其元循环求值器也很简单：\n根据 exp 类型，分别调用子函数求值 eval-if(exp, env) 判断 if 谓语真假，然后递归执行 if 模块或 else 模块 eval-assign eval-define 调用子函数，则 eval (exp, newEnv(vars, env))，使用新构造的执行环境 \u0026hellip; eval 求值器表较简单，但也很低效。比如对于递归阶乘的求解时，eval 求值器每次递归调用 eval 时都需要重新分析阶乘函数的语法。\n另一种求值方法是把语法分析和执行分离：(analyze (exp)) (env)。analyze(exp) 返回语法解析后的闭包，然后把环境 env 应用到闭包里。使用 analyze 对同一个过程只进行一次语法解析。\n惰性求值 我们所使用的语言里普遍支持惰性求值。比如在执行 if a \u0026amp;\u0026amp; f() {} 时，如果 a 是 false，则 f 不再被调用，rust 语言的 Option 类有两个方法，分别是：\nunwrap_or(val) 判断 Options 是否为空，为空，则返回入参 val unwrap_or_else(fn) 判断 Options 是否为空，为空，则返回闭包 fn 的执行结果 其中 wrap_or_else 使用的也是惰性求值的思想。 惰性求值的思想还可以用到其他场景：比如我们想要一个无穷的素数流，则可以用生成器函数，实现对下一个素数的惰性求值。\n寄存器机器的设计 寄存器机器包含两个要点：\n数据通路：寄存器的操作，比如把寄存器 r0 的值赋值给 r1，或者求两个寄存器的运算结果，并赋值给另外一个寄存器 控制器：控制指令的执行顺序 一个包含堆栈的寄存器的基本指令：\n设置 label：label 定义程序语句标签，可以使用 branch/goto 指令跳转 label 对应的指令位置 assign \u0026lt;register-name\u0026gt; \u0026lt;register-name\u0026gt; 把后面寄存器的值赋值给前面的寄存器内 例如：assign r0 r1 assign \u0026lt;register-name\u0026gt; \u0026lt;const\u0026gt; 把常量值赋值给寄存器 例如：assign r0 1 assign \u0026lt;register-name\u0026gt; \u0026lt;operation\u0026gt; 把表达式的值赋值给寄存器 例如 assign r0 (- r1 r2) 把 r1 - r2 的值赋值给 r0 assign r0 (\u0026gt; r1 r2) 把 r1 \u0026gt; r2 的结果赋值给 r0 寄存器 assign \u0026lt;register-name\u0026gt; \u0026lt;label\u0026gt; 把 label 对应语句指令的指针赋值给寄存器 例如：assign r0 gcd 把 gcd 标签语句指针赋值给 r0 寄存器 test \u0026lt;op\u0026gt; \u0026lt;register-name\u0026gt;|\u0026lt;const\u0026gt; \u0026lt;register-name\u0026gt;|\u0026lt;const\u0026gt; 用后面两个值，使用操作符 op 进行比较，并把比较结果保存到 flag 寄存器 例如：test = r0 1，判断 r0 与常数 1 是否相等 branch \u0026lt;label\u0026gt; 判断 flag 的值，如果为 true，则程序跳转到 label 位置 goto label|reg 直接跳转到 label 位置，或 register 存储的 label 位置 goto gcd goto r0 save \u0026lt;register-name\u0026gt; 把寄存器的值存入栈顶 save r0 restore \u0026lt;register-name\u0026gt; 从栈顶 pop 出数据，存入寄存器 restore r0 控制器从 pc 寄存器中读取指令行，并执行对应指令；指令顺序执行，pc 寄存器的值递增；goto，branch 语句控制 pc 寄存器的值，控制程序的跳转；直到没有指令需要执行时，程序结束。\n一段简单的寄存器指令代码：\n1 2 3 4 5 start ; 这个 label 不是必须，程序会从第一行执行 (assign r0 1) (assign r1 2) (assign r2 (+ r0 r1)) (print r2) 我用 go 语言实现了一个简单的寄存器模拟器，以及两个更复杂的寄存器程序案例 go-register-machine。\n解释器与编译器 为了能够在高级语言和寄存器语言的鸿沟上架起一道桥梁，通常存在着两种策略：\n解释器模式 编译模式 解释器模式就是使用上述寄存器语言实现一个解释器，它能循环读取高级语言，并实时运行。很多解释型语言都有命令行模式，比如 nodejs，python，php 等。\n编译器模式：可以使用任何语言实现编译器，它读取高级语言，并把它的过程翻译成寄存器语言。\n与解释方式相比，编译方式能够大大提高程序的执行效率。另一方面，解释器则为程序的开发和排查错误提供了一个更强大的环境，因为被执行的源代码在运行期间是可用的，可以取检查和修改。\n总结 以上只是我对书中的一些关键概念和案例做的摘要。书中还对流数据处理，非确定型计算等做了详细介绍，因为与我常用技术关联不大，所以这里没有涉及。书中对于元循环求值器，寄存器机器设计，解释器，编译器都有完整的 lisp 代码讲解，阅读这些源代码能够提升对程序执行原理的认识。\n本书毕竟是入门教材，书中所述的垃圾回收/寄存器程序/解释器/编译器等实现方式都比较简单，以达到浅显易懂的目的。我们日常使用的高级语言，其底层设计会更加复杂。阅读此书能帮助我们打开这扇门，里面更广阔的内容还需要不断探索。\n你可以在这里下载原书的 pdf 版。\n《计算机程序的构造和解释》Structure and Interpretation of Computer Programs(SICP) 作者：Harold Abels，Gerald Jay Sussman， Julie Sussman\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"Feb 04","permalink":"https://xiang-xx.github.io/posts/read-sicp/","tags":["阅读"],"title":"读《计算机程序的构造和解释》"},{"categories":null,"contents":"","date":"Jan 01","permalink":"https://xiang-xx.github.io/archives/","tags":null,"title":"Articles"}]